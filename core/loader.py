"""
HVDC ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ëª¨ë“ˆ - ìˆ˜ì •ëœ ë²„ì „
ì‹¤ì œ Excel íŒŒì¼ êµ¬ì¡°ì— ë§ì¶˜ ë°ì´í„° ì¶”ì¶œ
"""

import pandas as pd
import os
import glob
import re
from typing import List, Dict, Any, Optional
from datetime import datetime
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DataLoader:
    """HVDC ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ í´ë˜ìŠ¤ - ê°œì„ ëœ ë²„ì „"""
    
    def __init__(self):
        self.warehouse_mapping = {
            'DSV Al Markaz': ['markaz', 'm1', 'al markaz', 'almarkaz', 'al_markaz'],
            'DSV Indoor': ['indoor', 'm44', 'hauler indoor', 'hauler_indoor'],
            'DSV Outdoor': ['outdoor', 'out'],
            'MOSB': ['mosb'],
            'DSV MZP': ['mzp'],
            'DHL WH': ['dhl'],
            'AAA Storage': ['aaa']
        }
        
    def load_excel_files(self, data_dir: str = "data") -> Dict[str, pd.DataFrame]:
        """Excel íŒŒì¼ë“¤ì„ ë¡œë“œ (ê°œì„ ëœ ë²„ì „)"""
        excel_files = {}
        
        if not os.path.exists(data_dir):
            logger.error(f"ë°ì´í„° ë””ë ‰í† ë¦¬ ì—†ìŒ: {data_dir}")
            return excel_files
        
        # HVDC ì°½ê³  íŒŒì¼ íŒ¨í„´
        file_patterns = [
            "HVDC WAREHOUSE_HITACHI*.xlsx",
            "HVDC WAREHOUSE_SIMENSE*.xlsx"
        ]
        
        for pattern in file_patterns:
            for filepath in glob.glob(os.path.join(data_dir, pattern)):
                filename = os.path.basename(filepath)
                
                # ì¸ë³´ì´ìŠ¤ íŒŒì¼ ìŠ¤í‚µ
                if 'invoice' in filename.lower():
                    continue
                    
                try:
                    print(f"ğŸ“„ íŒŒì¼ ì²˜ë¦¬ ì¤‘: {filename}")
                    
                    # Excel íŒŒì¼ ë¡œë“œ
                    xl_file = pd.ExcelFile(filepath)
                    
                    # Case List ì‹œíŠ¸ ìš°ì„  ì„ íƒ
                    sheet_name = xl_file.sheet_names[0]
                    for sheet in xl_file.sheet_names:
                        if 'case' in sheet.lower() and 'list' in sheet.lower():
                            sheet_name = sheet
                            break
                    
                    df = pd.read_excel(filepath, sheet_name=sheet_name)
                    
                    if not df.empty:
                        excel_files[filename] = df
                        
                        # ê°„ë‹¨í•œ í†µê³„ ì¶œë ¥
                        date_cols = self._find_date_columns(df)
                        print(f"   ğŸ“… ë‚ ì§œ ì»¬ëŸ¼ {len(date_cols)}ê°œ ë°œê²¬")
                        
                        case_col = self._find_case_column(df)
                        if case_col:
                            case_count = df[case_col].nunique()
                            print(f"   ğŸ“¦ ê³ ìœ  ì¼€ì´ìŠ¤ {case_count}ê°œ")
                    
                except Exception as e:
                    logger.error(f"Excel íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {filename}: {e}")
                    
        return excel_files
    
    def extract_transactions(self, excel_files: Dict[str, pd.DataFrame]) -> List[Dict]:
        """Excel íŒŒì¼ë“¤ì—ì„œ íŠ¸ëœì­ì…˜ ë°ì´í„° ì¶”ì¶œ (ê°œì„ ëœ ë¡œì§)"""
        all_transactions = []
        
        for filename, df in excel_files.items():
            try:
                transactions = self._extract_file_transactions(df, filename)
                all_transactions.extend(transactions)
                print(f"   âœ… {len(transactions)}ê±´ ì´ë²¤íŠ¸ ì¶”ì¶œ")
                
            except Exception as e:
                logger.error(f"íŠ¸ëœì­ì…˜ ì¶”ì¶œ ì‹¤íŒ¨ {filename}: {e}")
                
        return all_transactions
    
    def _extract_file_transactions(self, df: pd.DataFrame, filename: str) -> List[Dict]:
        """ë‹¨ì¼ íŒŒì¼ì—ì„œ íŠ¸ëœì­ì…˜ ì¶”ì¶œ - Status ì»¬ëŸ¼ ì§€ì›"""
        transactions = []
        
        if df.empty:
            return transactions
        
        # í•µì‹¬ ì»¬ëŸ¼ ì°¾ê¸°
        case_col = self._find_case_column(df)
        qty_col = self._find_quantity_column(df)
        date_cols = self._find_date_columns(df)
        
        # ìƒˆë¡œìš´ Status ì»¬ëŸ¼ë“¤ ì°¾ê¸°
        status_cols = self._find_status_columns(df)
        
        if not case_col:
            logger.warning(f"ì¼€ì´ìŠ¤ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {filename}")
            return transactions
        
        if not date_cols:
            logger.warning(f"ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {filename}")
            return transactions
        
        # Qty ì „ì²˜ë¦¬
        if qty_col:
            df[qty_col] = self._normalize_quantities(df, case_col, qty_col)
        else:
            df['default_qty'] = 1
            qty_col = 'default_qty'
        
        # ê° í–‰ì— ëŒ€í•´ íŠ¸ëœì­ì…˜ ìƒì„±
        for idx, row in df.iterrows():
            case_id = str(row[case_col]) if pd.notna(row[case_col]) else f"CASE_{idx}"
            quantity = int(row[qty_col]) if pd.notna(row[qty_col]) else 1
            
            # Status ì •ë³´ ì¶”ì¶œ
            status_info = self._extract_status_info(row, status_cols)
            
            # ê° ë‚ ì§œ ì»¬ëŸ¼ì—ì„œ ì´ë²¤íŠ¸ ì¶”ì¶œ
            case_events = []
            
            for date_col in date_cols:
                if pd.notna(row[date_col]):
                    try:
                        event_date = pd.to_datetime(row[date_col])
                        warehouse = self._extract_warehouse_from_column(date_col)
                        
                        # Status ì •ë³´ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
                        if status_info.get('current_location'):
                            warehouse = status_info['current_location']
                        
                        if warehouse != 'UNKNOWN':
                            event_data = {
                                'case_id': case_id,
                                'date': event_date,
                                'warehouse': warehouse,
                                'quantity': quantity,
                                'source_column': date_col,
                                'status_info': status_info  # Status ì •ë³´ ì¶”ê°€
                            }
                            case_events.append(event_data)
                    except Exception as e:
                        logger.debug(f"ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ {date_col}: {e}")
                        continue
            
            # ì‹œê°„ìˆœ ì •ë ¬
            case_events.sort(key=lambda x: x['date'])
            
            # ì´ë²¤íŠ¸ë¥¼ íŠ¸ëœì­ì…˜ìœ¼ë¡œ ë³€í™˜
            for i, event in enumerate(case_events):
                # ì…ê³  ì´ë²¤íŠ¸ (ëª¨ë“  ìœ„ì¹˜ ë„ì°©)
                incoming_tx = {
                    'source_file': filename,
                    'timestamp': datetime.now(),
                    'data': {
                        'case': event['case_id'],
                        'date': event['date'],
                        'warehouse': event['warehouse'],
                        'incoming': event['quantity'],
                        'outgoing': 0,
                        'inventory': event['quantity'],
                        'status_warehouse': event['status_info'].get('warehouse', ''),
                        'status_site': event['status_info'].get('site', ''),
                        'status_current': event['status_info'].get('current', ''),
                        'status_location': event['status_info'].get('location', ''),
                        'status_storage': event['status_info'].get('storage', '')
                    }
                }
                transactions.append(incoming_tx)
                
                # ì¶œê³  ì´ë²¤íŠ¸ (ì´ì „ ìœ„ì¹˜ì—ì„œ)
                if i > 0:
                    prev_warehouse = case_events[i-1]['warehouse']
                    outgoing_tx = {
                        'source_file': filename,
                        'timestamp': datetime.now(),
                        'data': {
                            'case': event['case_id'],
                            'date': event['date'],
                            'warehouse': prev_warehouse,
                            'incoming': 0,
                            'outgoing': event['quantity'],
                            'inventory': 0,
                            'status_warehouse': event['status_info'].get('warehouse', ''),
                            'status_site': event['status_info'].get('site', ''),
                            'status_current': event['status_info'].get('current', ''),
                            'status_location': event['status_info'].get('location', ''),
                            'status_storage': event['status_info'].get('storage', '')
                        }
                    }
                    transactions.append(outgoing_tx)
        
        return transactions
    
    def _find_status_columns(self, df: pd.DataFrame) -> Dict[str, str]:
        """Status ê´€ë ¨ ì»¬ëŸ¼ë“¤ ì°¾ê¸°"""
        status_mapping = {}
        
        status_patterns = {
            'warehouse': ['status_warehouse', 'status warehouse'],
            'site': ['status_site', 'status site'],
            'current': ['status_current', 'status current'],
            'location': ['status_location', 'status location'],
            'storage': ['status_storage', 'status storage']
        }
        
        for col in df.columns:
            col_lower = str(col).lower().strip()
            for status_type, patterns in status_patterns.items():
                if any(pattern in col_lower for pattern in patterns):
                    status_mapping[status_type] = col
                    break
        
        return status_mapping
    
    def _extract_status_info(self, row: pd.Series, status_cols: Dict[str, str]) -> Dict[str, str]:
        """í–‰ì—ì„œ Status ì •ë³´ ì¶”ì¶œ"""
        status_info = {}
        
        for status_type, col_name in status_cols.items():
            if col_name in row.index and pd.notna(row[col_name]):
                status_info[status_type] = str(row[col_name]).strip()
        
        # í˜„ì¬ ìœ„ì¹˜ ê²°ì • ìš°ì„ ìˆœìœ„
        # 1. Status_Locationì´ ìˆìœ¼ë©´ ì‚¬ìš©
        # 2. Status_Currentê°€ ìˆìœ¼ë©´ ì‚¬ìš©  
        # 3. Status_Warehouse ì‚¬ìš©
        if status_info.get('location'):
            status_info['current_location'] = self._normalize_warehouse_name(status_info['location'])
        elif status_info.get('current'):
            status_info['current_location'] = self._normalize_warehouse_name(status_info['current'])
        elif status_info.get('warehouse'):
            status_info['current_location'] = self._normalize_warehouse_name(status_info['warehouse'])
        
        return status_info
    
    def _normalize_warehouse_name(self, raw_name: str) -> str:
        """ì°½ê³ ëª… ì •ê·œí™” - Status ì»¬ëŸ¼ìš©"""
        if pd.isna(raw_name) or not raw_name:
            return 'UNKNOWN'
            
        name_lower = str(raw_name).lower().strip()
        
        # ê¸°ì¡´ ë§¤í•‘ + Status íŠ¹í™” ë§¤í•‘
        warehouse_rules = {
            'DSV Al Markaz': ['markaz', 'm1', 'al markaz', 'almarkaz', 'al_markaz', 'dsv al markaz'],
            'DSV Indoor': ['indoor', 'm44', 'hauler indoor', 'hauler_indoor', 'dsv indoor'],
            'DSV Outdoor': ['outdoor', 'out', 'dsv outdoor'],
            'MOSB': ['mosb'],
            'DSV MZP': ['mzp', 'dsv mzp'],
            'DHL WH': ['dhl', 'dhl wh'],
            'AAA Storage': ['aaa', 'aaa storage'],
            'Storage': ['storage', 'ì°½ê³ '],  # Status ì»¬ëŸ¼ íŠ¹í™”
            'Site': ['site', 'ì‚¬ì´íŠ¸'],        # Status ì»¬ëŸ¼ íŠ¹í™”
        }
        
        for canonical, patterns in warehouse_rules.items():
            if any(pattern in name_lower for pattern in patterns):
                return canonical
        
        return str(raw_name).strip()
    
    def _find_case_column(self, df: pd.DataFrame) -> Optional[str]:
        """ì¼€ì´ìŠ¤ ì»¬ëŸ¼ ì°¾ê¸°"""
        case_patterns = ['case', 'carton', 'box', 'mr#', 'mr #', 'sct ship no', 'case no']
        
        for col in df.columns:
            col_lower = str(col).lower().strip()
            if any(pattern in col_lower for pattern in case_patterns):
                return col
        return None
    
    def _normalize_text_for_matching(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ê·œí™” - ëŒ€ì†Œë¬¸ì, ë³µìˆ˜í˜•, ì†Œìœ ê²© í†µì¼"""
        if pd.isna(text) or not text:
            return ""
        
        normalized = str(text).strip()
        
        # 1. ëŒ€ì†Œë¬¸ì í†µì¼ (ì†Œë¬¸ìë¡œ)
        normalized = normalized.lower()
        
        # 2. íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ê³µë°± ì •ë¦¬
        import re
        normalized = re.sub(r'[\'\"â€™]', '', normalized)  # ë”°ì˜´í‘œ ì œê±°
        normalized = re.sub(r'[^\w\s]', ' ', normalized)   # íŠ¹ìˆ˜ë¬¸ìë¥¼ ê³µë°±ìœ¼ë¡œ
        normalized = re.sub(r'\s+', ' ', normalized)       # ì—°ì† ê³µë°± ì œê±°
        normalized = normalized.strip()
        
        # 3. ë³µìˆ˜í˜• ì •ê·œí™” (s ì œê±°)
        if normalized.endswith('s') and len(normalized) > 2:
            # ì¼ë°˜ì ì¸ ë³µìˆ˜í˜• ì²˜ë¦¬
            if normalized.endswith('ies'):
                normalized = normalized[:-3] + 'y'  # companies -> company
            elif normalized.endswith('es') and len(normalized) > 3:
                if normalized[-3] in 'sxz' or normalized.endswith('ches') or normalized.endswith('shes'):
                    normalized = normalized[:-2]     # boxes -> box, dishes -> dish
                else:
                    normalized = normalized[:-1]     # cases -> case
            elif not normalized.endswith('ss'):     # glassëŠ” ê·¸ëŒ€ë¡œ
                normalized = normalized[:-1]         # pkgs -> pkg
        
        # 4. ì•½ì–´ í‘œì¤€í™”
        abbreviation_map = {
            'pkg': 'package',
            'qty': 'quantity', 
            'q ty': 'quantity',
            'pcs': 'pieces',
            'pc': 'piece',
            'ea': 'each',
            'no': 'number',
            'wh': 'warehouse',
            'mr': 'material request'
        }
        
        for abbr, full in abbreviation_map.items():
            if normalized == abbr or normalized.startswith(abbr + ' '):
                normalized = normalized.replace(abbr, full, 1)
        
        return normalized.strip()
    
    def _find_quantity_column(self, df: pd.DataFrame) -> Optional[str]:
        """ìˆ˜ëŸ‰ ì»¬ëŸ¼ ì°¾ê¸° - ì •ê·œí™”ëœ íŒ¨í„´ ë§¤ì¹­"""
        quantity_patterns = [
            # ê¸°ë³¸ ìˆ˜ëŸ‰ íŒ¨í„´ (ì •ê·œí™” ì „)
            'q\'ty', 'qty', 'quantity', 'received', 'pieces', 'piece',
            # PKG ê´€ë ¨ ëª¨ë“  ë³€í˜•
            'pkg', 'pkgs', 'pkg\'s', 'package', 'packages', 'package\'s',
            'PKG', 'PKGS', 'PKG\'S', 'PACKAGE', 'PACKAGES', 'PACKAGE\'S',
            'Pkg', 'Pkgs', 'Pkg\'s', 'Package', 'Packages', 'Package\'s',
            # ê¸°íƒ€ ìˆ˜ëŸ‰ ê´€ë ¨
            'pcs', 'pc', 'pieces', 'piece', 'ea', 'each', 'count', 'cnt', 'p\'kg'
        ]
        
        # ì •ê·œí™”ëœ íŒ¨í„´ìœ¼ë¡œ ë³€í™˜
        normalized_patterns = [self._normalize_text_for_matching(p) for p in quantity_patterns]
        
        for col in df.columns:
            col_normalized = self._normalize_text_for_matching(str(col))
            
            # ì •í™•í•œ ë§¤ì¹­
            if col_normalized in normalized_patterns:
                logger.debug(f"ìˆ˜ëŸ‰ ì»¬ëŸ¼ ë°œê²¬ (ì •í™• ë§¤ì¹­): {col} â†’ {col_normalized}")
                return col
            
            # ë¶€ë¶„ ë§¤ì¹­ (ì»¬ëŸ¼ëª…ì— íŒ¨í„´ì´ í¬í•¨ëœ ê²½ìš°)
            for pattern in normalized_patterns:
                if pattern and (pattern in col_normalized or col_normalized in pattern):
                    logger.debug(f"ìˆ˜ëŸ‰ ì»¬ëŸ¼ ë°œê²¬ (ë¶€ë¶„ ë§¤ì¹­): {col} â†’ {col_normalized} (íŒ¨í„´: {pattern})")
                    return col
        
        return None
    
    def _find_date_columns(self, df: pd.DataFrame) -> List[str]:
        """ë‚ ì§œ ì»¬ëŸ¼ ì°¾ê¸° (ê°œì„ ëœ ë¡œì§)"""
        date_columns = []
        
        for col in df.columns:
            # 1. ì»¬ëŸ¼ëª…ì— ì°½ê³ ëª…ì´ í¬í•¨ëœ ê²½ìš°
            warehouse = self._extract_warehouse_from_column(col)
            if warehouse != 'UNKNOWN':
                # ì‹¤ì œ ë‚ ì§œ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                sample_values = df[col].dropna().head(5)
                if len(sample_values) > 0:
                    date_count = 0
                    for val in sample_values:
                        if self._is_date_like(str(val)):
                            date_count += 1
                    
                    # 50% ì´ìƒì´ ë‚ ì§œ í˜•ì‹ì´ë©´ ë‚ ì§œ ì»¬ëŸ¼ìœ¼ë¡œ ì¸ì •
                    if date_count >= len(sample_values) * 0.5:
                        date_columns.append(col)
        
        return date_columns
    
    def _extract_warehouse_from_column(self, col_name: str) -> str:
        """ì»¬ëŸ¼ëª…ì—ì„œ ì°½ê³ ëª… ì¶”ì¶œ"""
        col_lower = str(col_name).lower().strip()
        
        # ë‚ ì§œ ê´€ë ¨ í‚¤ì›Œë“œ ì œê±°
        date_keywords = ['eta', 'etd', 'ata', 'atd', 'date', 'time', 'arrival', 'departure']
        for keyword in date_keywords:
            col_lower = col_lower.replace(keyword, '').strip()
        
        # ì°½ê³  ë§¤í•‘ í™•ì¸
        for warehouse, patterns in self.warehouse_mapping.items():
            for pattern in patterns:
                if pattern in col_lower:
                    return warehouse
        
        return 'UNKNOWN'
    
    def _is_date_like(self, value: str) -> bool:
        """ë¬¸ìì—´ì´ ë‚ ì§œ í˜•ì‹ì¸ì§€ í™•ì¸"""
        date_patterns = [
            r'\d{4}-\d{2}-\d{2}',  # 2024-01-01
            r'\d{2}/\d{2}/\d{4}',  # 01/01/2024
            r'\d{1,2}/\d{1,2}/\d{4}',  # 1/1/2024
            r'\d{4}/\d{2}/\d{2}',  # 2024/01/01
        ]
        
        for pattern in date_patterns:
            if re.search(pattern, str(value)):
                return True
                
        # pandasë¡œ ë‚ ì§œ íŒŒì‹± ì‹œë„
        try:
            pd.to_datetime(value)
            return True
        except:
            return False
    
    def _normalize_quantities(self, df: pd.DataFrame, case_col: str, qty_col: str) -> pd.Series:
        """ìˆ˜ëŸ‰ ì •ê·œí™” (ì¼€ì´ìŠ¤ë³„ ì „íŒŒ) - ì¸ë±ìŠ¤ ì•ˆì „ ì²˜ë¦¬"""
        qty_series = pd.to_numeric(df[qty_col], errors='coerce')
        
        # 0ì„ NaNìœ¼ë¡œ ë³€í™˜
        qty_series = qty_series.replace(0, pd.NA)
        
        try:
            # ì¼€ì´ìŠ¤ë³„ ì „íŒŒ (pandas 2.0+ í˜¸í™˜, ì¸ë±ìŠ¤ ì•ˆì „)
            df_temp = df[[case_col]].copy()
            df_temp['qty'] = qty_series
            
            # ì¼€ì´ìŠ¤ë³„ ê·¸ë£¹í•‘í•˜ì—¬ forward/backward fill
            filled_values = df_temp.groupby(case_col)['qty'].transform(
                lambda x: x.ffill().bfill()
            )
            
            # ì›ë³¸ ì¸ë±ìŠ¤ ìœ ì§€í•˜ë©´ì„œ ê²°ê³¼ ë°˜í™˜
            result = filled_values.fillna(1).astype(int)
            
        except Exception as e:
            logger.warning(f"ìˆ˜ëŸ‰ ì •ê·œí™” ì‹¤íŒ¨: {e}, ê¸°ë³¸ê°’ ì‚¬ìš©")
            result = pd.Series([1] * len(df), index=df.index)
        
        return result
    
    def get_summary_statistics(self, transactions: List[Dict]) -> Dict[str, Any]:
        """ì¶”ì¶œëœ íŠ¸ëœì­ì…˜ ìš”ì•½ í†µê³„"""
        if not transactions:
            return {}
        
        # ì°½ê³ ë³„ ì§‘ê³„
        warehouse_counts = {}
        total_incoming = 0
        total_outgoing = 0
        
        for tx in transactions:
            data = tx.get('data', {})
            warehouse = data.get('warehouse', 'UNKNOWN')
            
            if warehouse not in warehouse_counts:
                warehouse_counts[warehouse] = 0
            warehouse_counts[warehouse] += 1
            
            total_incoming += data.get('incoming', 0)
            total_outgoing += data.get('outgoing', 0)
        
        # ë‚ ì§œ ë²”ìœ„
        dates = []
        for tx in transactions:
            date = tx.get('data', {}).get('date')
            if date:
                dates.append(date)
        
        return {
            'total_transactions': len(transactions),
            'total_incoming': total_incoming,
            'total_outgoing': total_outgoing,
            'warehouse_distribution': warehouse_counts,
            'date_range': {
                'start': min(dates) if dates else None,
                'end': max(dates) if dates else None
            },
            'unique_cases': len(set(tx['data'].get('case', '') for tx in transactions if 'case' in tx.get('data', {})))
        } 