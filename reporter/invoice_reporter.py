#!/usr/bin/env python3
"""
HVDC ì˜¨í†¨ë¡œì§€â†’ë§¤í•‘â†’í•¨ìˆ˜ ì ìš©â†’ìµœì¢… 8ê°œ ì‹œíŠ¸ ë¦¬í¬íŠ¸
=====================================

ì „ì²´ ìë™í™” íŒŒì´í”„ë¼ì¸:
ì˜¨í†¨ë¡œì§€ ë°ì´í„° â†’ í•„ë“œ ë§¤í•‘ â†’ ë³€í™˜/ì •ê·œí™” â†’ BI ë¶„ì„ â†’ 8ì‹œíŠ¸ Excel ë¦¬í¬íŠ¸

í•„ìˆ˜: ê° ë¦¬í¬íŠ¸ì˜ "ì›”ë³„" ì§‘ê³„ëŠ” ë¬´ì¡°ê±´ ë°ì´í„° ë‚´ "ëª¨ë“  ì›”"ì´ ë¹ ì§ì—†ì´ ë‚˜ì™€ì•¼ í•˜ë¯€ë¡œ,
pivot/table ì‘ì„± ì‹œ ì „ì²´ ì›”(month range) ê¸°ì¤€ìœ¼ë¡œ ì¬ìƒ‰ì¸/ê²°ì¸¡ 0 ì±„ìš°ê¸°ê¹Œì§€ ë°˜ì˜
"""

import pandas as pd
import json
import numpy as np
from datetime import datetime
import sys
from pathlib import Path
import xlsxwriter

# ===============================================================================
# 1. ì˜¨í†¨ë¡œì§€â†’ë§¤í•‘: DataFrame ë³€í™˜
# ===============================================================================

def load_ontology_mapping_data():
    """
    ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ ë°ì´í„°ì…‹ ì¤€ë¹„ ë° ìµœì‹  ë§¤í•‘ ê·œì¹™ìœ¼ë¡œ í‘œì¤€ ì»¬ëŸ¼ ë§¤í•‘
    """
    print("ğŸ”„ 1ë‹¨ê³„: ì˜¨í†¨ë¡œì§€â†’ë§¤í•‘ DataFrame ë³€í™˜ ì‹œì‘...")
    
    # 1) ë§¤í•‘ ê·œì¹™ ë¡œë”© (14ê°œ ì£¼ìš” í•„ë“œ)
    with open("mapping_rules_v2.6_unified.json", encoding="utf-8") as f:
        mapping_rules = json.load(f)["field_map"]
    
    print(f"âœ… ë§¤í•‘ ê·œì¹™ ë¡œë“œ ì™„ë£Œ: {len(mapping_rules)}ê°œ í•„ë“œ")
    
    # 2) ì›ë³¸ DataFrame ì»¬ëŸ¼ì„ ë§¤í•‘
    df_raw = pd.read_excel("data/HVDC WAREHOUSE_HITACHI(HE).xlsx")  # ì˜ˆì‹œ
    col_map = {k: v for k, v in mapping_rules.items() if k in df_raw.columns}
    df = df_raw.rename(columns=col_map)
    
    print(f"âœ… ì»¬ëŸ¼ ë§¤í•‘ ì™„ë£Œ: {len(col_map)}ê°œ í•„ë“œ ë§¤í•‘ë¨")
    
    # 3) ì‹¤ë¬´ìš© í‘œì¤€ ì»¬ëŸ¼ëª… ìœ ì§€, í•„ìš” í•„ë“œ ëˆ„ë½ ì‹œ ìƒì„±(0/ë¹ˆê°’)
    for needed in mapping_rules.values():
        if needed not in df.columns:
            df[needed] = 0  # í˜¹ì€ np.nan, "" ë“±
    
    # 4) ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬ (ETD/ATA ë“±ì„ ê¸°ì¤€ìœ¼ë¡œ ì›”ë³„ ì§‘ê³„ìš© ë‚ ì§œ ìƒì„±)
    date_cols = ['ETD/ATD', 'ETA/ATA']
    valid_dates = []
    
    for col in date_cols:
        if col in df_raw.columns:
            valid_dates.extend(pd.to_datetime(df_raw[col], errors='coerce').dropna())
    
    if valid_dates:
        # ì²« ë²ˆì§¸ ìœ íš¨í•œ ë‚ ì§œ ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ ì›”ë³„ ì§‘ê³„ìš© ë‚ ì§œ ìƒì„±
        df['hasDate'] = pd.to_datetime(df_raw[date_cols[0]], errors='coerce')
        # ê²°ì¸¡ê°’ì€ í˜„ì¬ ë‚ ì§œë¡œ ì±„ì›€
        df['hasDate'] = df['hasDate'].fillna(pd.Timestamp.now())
    else:
        # ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ í˜„ì¬ ë‚ ì§œ ì‚¬ìš©
        df['hasDate'] = pd.Timestamp.now()
    
    print(f"âœ… í‘œì¤€í™” ì™„ë£Œ: {len(df)}ê±´ ë°ì´í„°, {len(df.columns)}ê°œ ì»¬ëŸ¼")
    
    return df, mapping_rules

# ===============================================================================
# 2. ì „ì²˜ë¦¬Â·ì •ê·œí™” ë° ì›”ë³„ ì§‘ê³„ ì „ì²´ì›” ë³´ì¥
# ===============================================================================

def prepare_monthly_aggregation(df):
    """
    ì›”ë³„ ì§‘ê³„ë¥¼ ìœ„í•œ ì „ì²˜ë¦¬ ë° ì „ì²´ì›” ì¸ë±ìŠ¤ ìƒì„±
    """
    print("ğŸ”„ 2ë‹¨ê³„: ì „ì²˜ë¦¬Â·ì •ê·œí™” ë° ì›”ë³„ ì§‘ê³„ ì „ì²´ì›” ë³´ì¥...")
    
    # 1) ëª¨ë“  ì›” êµ¬í•˜ê¸° (ex: 2024-01 ~ 2025-06)
    df['Billing Month'] = pd.to_datetime(df['hasDate']).dt.to_period("M")
    all_months = pd.period_range(df['Billing Month'].min(), df['Billing Month'].max(), freq='M')
    
    print(f"âœ… ì „ì²´ ì›” ë²”ìœ„: {all_months[0]} ~ {all_months[-1]} ({len(all_months)}ê°œì›”)")
    
    # 2) ê¸°ë³¸ ì§‘ê³„ìš© ì»¬ëŸ¼ ì¶”ê°€
    df['hasAmount_numeric'] = pd.to_numeric(df['hasAmount'], errors='coerce').fillna(0)
    df['hasVolume_numeric'] = pd.to_numeric(df['hasVolume'], errors='coerce').fillna(0)
    
    return df, all_months

# ===============================================================================
# 3. 8ê°œ ì‹œíŠ¸ë³„ ë¦¬í¬íŠ¸ ìƒì„± í•¨ìˆ˜ë“¤
# ===============================================================================

def create_monthly_dashboard(df, all_months):
    """1. ì›”ë³„_ì „ì²´í˜„í™© - KPI ëŒ€ì‹œë³´ë“œ + ì…ì¶œê³  í˜„í™©"""
    print("ğŸ“Š ì‹œíŠ¸ 1: ì›”ë³„_ì „ì²´í˜„í™© ìƒì„±...")
    
    # KPI, ì…ì¶œê³ , ê¸ˆì•¡ ë“± ì§‘ê³„
    df['month'] = pd.to_datetime(df['hasDate']).dt.to_period("M")
    
    monthly_kpi = df.groupby('month').agg({
        'hasAmount_numeric': ['count', 'sum', 'mean'],
        'hasVolume_numeric': ['sum', 'mean'],
        'hasSite': 'nunique',
        'hasShipmentNo': 'nunique'
    }).round(2)
    
    # ì»¬ëŸ¼ëª… ì •ë¦¬
    monthly_kpi.columns = ['ê±°ë˜ê±´ìˆ˜', 'ì´ê¸ˆì•¡', 'í‰ê· ê¸ˆì•¡', 'ì´ë¶€í”¼', 'í‰ê· ë¶€í”¼', 'í˜„ì¥ìˆ˜', 'ì†¡ì¥ìˆ˜']
    
    # ì „ì²´ì›” ê¸°ì¤€ìœ¼ë¡œ reindex (ëˆ„ë½ëœ ì›”ì€ 0ìœ¼ë¡œ ì±„ì›€)
    monthly_kpi = monthly_kpi.reindex(all_months, fill_value=0)
    
    return monthly_kpi

def create_supplier_report(df, all_months):
    """2. ê³µê¸‰ì‚¬ë³„_ì›”ë³„í˜„í™© - ê³µê¸‰ì‚¬ ì„±ê³¼ ì¶”ì  + ë‹¨ê°€ ë¶„ì„"""
    print("ğŸ“Š ì‹œíŠ¸ 2: ê³µê¸‰ì‚¬ë³„_ì›”ë³„í˜„í™© ìƒì„±...")
    
    df['month'] = pd.to_datetime(df['hasDate']).dt.to_period("M")
    
    # ê³µê¸‰ì‚¬ë¥¼ Siteë¡œ ê°€ì • (ì‹¤ì œë¡œëŠ” ê³µê¸‰ì‚¬ ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•¨)
    supplier_pivot = df.pivot_table(
        index='hasSite',
        columns='month', 
        values='hasAmount_numeric',
        aggfunc='sum',
        fill_value=0
    )
    
    # ì „ì²´ì›” ê¸°ì¤€ìœ¼ë¡œ reindex
    supplier_pivot = supplier_pivot.reindex(columns=all_months, fill_value=0)
    
    # í•©ê³„ ë° í‰ê·  ì¶”ê°€
    supplier_pivot['ì´í•©ê³„'] = supplier_pivot.sum(axis=1)
    supplier_pivot['ì›”í‰ê· '] = supplier_pivot.iloc[:, :-1].mean(axis=1).round(2)
    
    return supplier_pivot

def create_warehouse_report(df, all_months):
    """3. ì°½ê³ ë³„_ì›”ë³„í˜„í™© - ì°½ê³  ìš´ì˜ íš¨ìœ¨ì„± + íšŒì „ìœ¨"""
    print("ğŸ“Š ì‹œíŠ¸ 3: ì°½ê³ ë³„_ì›”ë³„í˜„í™© ìƒì„±...")
    
    # ë‚ ì§œê°€ datetime ì•„ë‹Œ ê²½ìš° ë³€í™˜
    df['Month'] = pd.to_datetime(df['hasDate']).dt.to_period("M")
    
    # ì°½ê³  ì»¬ëŸ¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (hasSiteë¥¼ ì°½ê³ ë¡œ ì‚¬ìš©)
    if 'hasSite' in df.columns:
        # ì°½ê³ ë³„ x ì›”ë³„ Qty í•©ê³„ (pivot_table ì‚¬ìš©)
        warehouse_monthly = df.pivot_table(
            index='hasSite',
            columns='Month',
            values='hasAmount_numeric',
            aggfunc='sum',
            fill_value=0
        )
        
        # ì°½ê³ ë³„ ì´í•©, ë¶€í”¼ ë“± ì¶”ê°€
        warehouse_monthly['ê¸ˆì•¡í•©ê³„'] = df.groupby('hasSite')['hasAmount_numeric'].sum()
        warehouse_monthly['ë¶€í”¼í•©ê³„'] = df.groupby('hasSite')['hasVolume_numeric'].sum()
        warehouse_monthly['ê±´ìˆ˜'] = df.groupby('hasSite').size()
        
        # ì›”ë³„ ì»¬ëŸ¼ ìˆœì„œ ë³´ì¥(ì „ì²´ì›”)
        warehouse_monthly = warehouse_monthly.reindex(columns=list(all_months) + ['ê¸ˆì•¡í•©ê³„', 'ë¶€í”¼í•©ê³„', 'ê±´ìˆ˜'], fill_value=0)
        
        # ì¸ë±ìŠ¤(ì°½ê³ ëª…)ë„ ì»¬ëŸ¼ìœ¼ë¡œ
        warehouse_monthly = warehouse_monthly.reset_index().rename(columns={'hasSite': 'ì°½ê³ ëª…'})
        
    else:
        # ê¸°ë³¸ ë”ë¯¸ ë°ì´í„° (pivot_table êµ¬ì¡°ì™€ ì¼ì¹˜)
        warehouse_monthly = pd.DataFrame({
            'ì°½ê³ ëª…': ['DSV Indoor', 'DSV Outdoor', 'DAS'],
            'ê¸ˆì•¡í•©ê³„': [0, 0, 0],
            'ë¶€í”¼í•©ê³„': [0, 0, 0], 
            'ê±´ìˆ˜': [0, 0, 0]
        })
        # ëª¨ë“  ì›” ì»¬ëŸ¼ ì¶”ê°€
        for month in all_months:
            warehouse_monthly[str(month)] = 0
    
    return warehouse_monthly

def create_site_report(df, all_months):
    """4. í˜„ì¥ë³„_ì›”ë³„í˜„í™© - í˜„ì¥ ë°°ì†¡ í˜„í™© + ë¹ˆë„ ë¶„ì„"""
    print("ğŸ“Š ì‹œíŠ¸ 4: í˜„ì¥ë³„_ì›”ë³„í˜„í™© ìƒì„±...")
    
    df['month'] = pd.to_datetime(df['hasDate']).dt.to_period("M")
    
    site_pivot = df.pivot_table(
        index='hasSite',
        columns='month',
        values='hasVolume_numeric',
        aggfunc=['sum', 'count'],
        fill_value=0
    )
    
    # ì „ì²´ì›” ê¸°ì¤€ìœ¼ë¡œ reindex
    if not site_pivot.empty:
        site_pivot = site_pivot.reindex(columns=all_months, level=1, fill_value=0)
    else:
        # ë”ë¯¸ ë°ì´í„°
        site_pivot = pd.DataFrame(index=['Site1', 'Site2'], columns=all_months)
        site_pivot = site_pivot.fillna(0)
    
    return site_pivot

def create_inbound_report(df, all_months):
    """5. ì…ê³ í˜„í™©_ì›”ë³„ - ì…ê³  íŒ¨í„´ + ìš”ì¼ë³„ ë¶„ì„"""
    print("ğŸ“Š ì‹œíŠ¸ 5: ì…ê³ í˜„í™©_ì›”ë³„ ìƒì„±...")
    
    df['month'] = pd.to_datetime(df['hasDate']).dt.to_period("M")
    df['weekday'] = pd.to_datetime(df['hasDate']).dt.day_name()
    
    # ì…ê³ ëŠ” ì–‘ìˆ˜ ê¸ˆì•¡ìœ¼ë¡œ ê°€ì •
    inbound_data = df[df['hasAmount_numeric'] > 0].copy()
    
    inbound_monthly = inbound_data.groupby('month').agg({
        'hasAmount_numeric': ['count', 'sum'],
        'hasVolume_numeric': 'sum'
    }).round(2)
    
    inbound_monthly.columns = ['ì…ê³ ê±´ìˆ˜', 'ì…ê³ ê¸ˆì•¡', 'ì…ê³ ë¶€í”¼']
    inbound_monthly = inbound_monthly.reindex(all_months, fill_value=0)
    
    # ìš”ì¼ë³„ íŒ¨í„´ ì¶”ê°€
    weekday_pattern = inbound_data.groupby('weekday')['hasAmount_numeric'].count()
    
    return inbound_monthly, weekday_pattern

def create_outbound_report(df, all_months):
    """6. ì¶œê³ í˜„í™©_ì›”ë³„ - ì¶œê³  ìœ í˜•ë³„ + TRANSFER vs FINAL"""
    print("ğŸ“Š ì‹œíŠ¸ 6: ì¶œê³ í˜„í™©_ì›”ë³„ ìƒì„±...")
    
    df['month'] = pd.to_datetime(df['hasDate']).dt.to_period("M")
    
    # ì¶œê³  íƒ€ì… êµ¬ë¶„ (ì‹¤ì œë¡œëŠ” transaction type ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•¨)
    # ì—¬ê¸°ì„œëŠ” ì„ì‹œë¡œ volume ê¸°ì¤€ìœ¼ë¡œ êµ¬ë¶„
    df['ì¶œê³ íƒ€ì…'] = np.where(df['hasVolume_numeric'] > df['hasVolume_numeric'].median(), 'TRANSFER', 'FINAL')
    
    outbound_pivot = df.pivot_table(
        index='ì¶œê³ íƒ€ì…',
        columns='month',
        values='hasAmount_numeric',
        aggfunc='sum',
        fill_value=0
    )
    
    outbound_pivot = outbound_pivot.reindex(columns=all_months, fill_value=0)
    
    return outbound_pivot

def create_inventory_report(df, all_months):
    """7. ì¬ê³ í˜„í™©_ì›”ë³„ - ì¬ê³  Aging + íšŒì „ìœ¨ ë¶„ì„"""
    print("ğŸ“Š ì‹œíŠ¸ 7: ì¬ê³ í˜„í™©_ì›”ë³„ ìƒì„±...")
    
    df['month'] = pd.to_datetime(df['hasDate']).dt.to_period("M")
    
    # ì¬ê³  aging ê³„ì‚° (í˜„ì¬ ë‚ ì§œ ê¸°ì¤€)
    df['aging_days'] = (pd.Timestamp.now() - pd.to_datetime(df['hasDate'])).dt.days
    df['aging_category'] = pd.cut(df['aging_days'], 
                                  bins=[0, 30, 90, 180, float('inf')], 
                                  labels=['30ì¼ì´í•˜', '31-90ì¼', '91-180ì¼', '180ì¼ì´ˆê³¼'])
    
    inventory_aging = df.pivot_table(
        index='aging_category',
        columns='month',
        values='hasAmount_numeric',
        aggfunc='sum',
        fill_value=0
    )
    
    inventory_aging = inventory_aging.reindex(columns=all_months, fill_value=0)
    
    return inventory_aging

def create_billing_verification_report(df, all_months):
    """8. ì²­êµ¬ë§¤ì¹­_ê²€ì¦ - ì†¡ì¥-í™”ë¬¼ ë§¤ì¹­ + ì°¨ì•¡ ë¶„ì„"""
    print("ğŸ“Š ì‹œíŠ¸ 8: ì²­êµ¬ë§¤ì¹­_ê²€ì¦ ìƒì„±...")
    
    df['month'] = pd.to_datetime(df['hasDate']).dt.to_period("M")
    
    # 5%/15% í—ˆìš© ì˜¤ì°¨ ê¸°ì¤€ìœ¼ë¡œ ë§¤ì¹­ ê²€ì¦
    df['expected_amount'] = df['hasVolume_numeric'] * 100  # ê°€ì •: ë¶€í”¼ * 100 = ì˜ˆìƒê¸ˆì•¡
    df['amount_diff'] = df['hasAmount_numeric'] - df['expected_amount']
    df['diff_percentage'] = (df['amount_diff'] / df['expected_amount'] * 100).abs()
    
    # ì˜¤ì°¨ ë²”ìœ„ë³„ ë¶„ë¥˜
    df['match_status'] = pd.cut(df['diff_percentage'], 
                               bins=[0, 5, 15, float('inf')], 
                               labels=['ì •í™•ë§¤ì¹­(5%ì´ë‚´)', 'í—ˆìš©ì˜¤ì°¨(5-15%)', 'ì˜¤ì°¨ì´ˆê³¼(15%ì´ìƒ)'])
    
    billing_verification = df.pivot_table(
        index='match_status',
        columns='month',
        values='hasAmount_numeric',
        aggfunc='count',
        fill_value=0
    )
    
    billing_verification = billing_verification.reindex(columns=all_months, fill_value=0)
    
    return billing_verification

# ===============================================================================
# 4. Excel ì €ì¥: 8ê°œ ì‹œíŠ¸/ì¡°ê±´ë¶€ì„œì‹ í¬í•¨
# ===============================================================================

def apply_conditional_formatting(workbook, worksheet, df, sheet_name):
    """ì¡°ê±´ë¶€ ì„œì‹ ì ìš©"""
    
    if df.empty:
        return
    
    nrows, ncols = df.shape
    
    # 3-Color Scale ì¡°ê±´ë¶€ ì„œì‹
    worksheet.conditional_format(1, 1, nrows, ncols-1, {
        "type": "3_color_scale",
        "min_color": "#F8696B",  # ë¹¨ê°• (ìµœì†Œê°’)
        "mid_color": "#FFEB84",  # ë…¸ë‘ (ì¤‘ê°„ê°’) 
        "max_color": "#63BE7B",  # ë…¹ìƒ‰ (ìµœëŒ€ê°’)
    })
    
    # ìˆ«ì í¬ë§· ì ìš©
    num_format = workbook.add_format({"num_format": "#,##0.00"})
    worksheet.set_column(1, ncols-1, 12, num_format)

def save_8sheet_excel_report(df, all_months, output_path="HVDC_8Sheet_BI_Report.xlsx"):
    """8ê°œ ì‹œíŠ¸ Excel ë¦¬í¬íŠ¸ ì €ì¥"""
    print("ğŸ’¾ 4ë‹¨ê³„: Excel ì €ì¥ - 8ê°œ ì‹œíŠ¸/ì¡°ê±´ë¶€ì„œì‹ í¬í•¨...")
    
    with pd.ExcelWriter(output_path, engine="xlsxwriter") as writer:
        workbook = writer.book
        
        # 1. ì›”ë³„_ì „ì²´í˜„í™©
        monthly_dashboard = create_monthly_dashboard(df, all_months)
        monthly_dashboard.to_excel(writer, sheet_name="01_ì›”ë³„_ì „ì²´í˜„í™©")
        ws1 = writer.sheets["01_ì›”ë³„_ì „ì²´í˜„í™©"]
        apply_conditional_formatting(workbook, ws1, monthly_dashboard, "01_ì›”ë³„_ì „ì²´í˜„í™©")
        
        # 2. ê³µê¸‰ì‚¬ë³„_ì›”ë³„í˜„í™©  
        supplier_report = create_supplier_report(df, all_months)
        supplier_report.to_excel(writer, sheet_name="02_ê³µê¸‰ì‚¬ë³„_ì›”ë³„í˜„í™©")
        ws2 = writer.sheets["02_ê³µê¸‰ì‚¬ë³„_ì›”ë³„í˜„í™©"]
        apply_conditional_formatting(workbook, ws2, supplier_report, "02_ê³µê¸‰ì‚¬ë³„_ì›”ë³„í˜„í™©")
        
        # 3. ì°½ê³ ë³„_ì›”ë³„í˜„í™©
        warehouse_report = create_warehouse_report(df, all_months)
        warehouse_report.to_excel(writer, sheet_name="03_ì°½ê³ ë³„_ì›”ë³„í˜„í™©")
        ws3 = writer.sheets["03_ì°½ê³ ë³„_ì›”ë³„í˜„í™©"] 
        apply_conditional_formatting(workbook, ws3, warehouse_report, "03_ì°½ê³ ë³„_ì›”ë³„í˜„í™©")
        
        # 4. í˜„ì¥ë³„_ì›”ë³„í˜„í™©
        site_report = create_site_report(df, all_months)
        site_report.to_excel(writer, sheet_name="04_í˜„ì¥ë³„_ì›”ë³„í˜„í™©")
        ws4 = writer.sheets["04_í˜„ì¥ë³„_ì›”ë³„í˜„í™©"]
        apply_conditional_formatting(workbook, ws4, site_report, "04_í˜„ì¥ë³„_ì›”ë³„í˜„í™©")
        
        # 5. ì…ê³ í˜„í™©_ì›”ë³„
        inbound_report, weekday_pattern = create_inbound_report(df, all_months)
        inbound_report.to_excel(writer, sheet_name="05_ì…ê³ í˜„í™©_ì›”ë³„")
        ws5 = writer.sheets["05_ì…ê³ í˜„í™©_ì›”ë³„"]
        apply_conditional_formatting(workbook, ws5, inbound_report, "05_ì…ê³ í˜„í™©_ì›”ë³„")
        
        # 6. ì¶œê³ í˜„í™©_ì›”ë³„
        outbound_report = create_outbound_report(df, all_months)
        outbound_report.to_excel(writer, sheet_name="06_ì¶œê³ í˜„í™©_ì›”ë³„")
        ws6 = writer.sheets["06_ì¶œê³ í˜„í™©_ì›”ë³„"]
        apply_conditional_formatting(workbook, ws6, outbound_report, "06_ì¶œê³ í˜„í™©_ì›”ë³„")
        
        # 7. ì¬ê³ í˜„í™©_ì›”ë³„
        inventory_report = create_inventory_report(df, all_months)
        inventory_report.to_excel(writer, sheet_name="07_ì¬ê³ í˜„í™©_ì›”ë³„")
        ws7 = writer.sheets["07_ì¬ê³ í˜„í™©_ì›”ë³„"]
        apply_conditional_formatting(workbook, ws7, inventory_report, "07_ì¬ê³ í˜„í™©_ì›”ë³„")
        
        # 8. ì²­êµ¬ë§¤ì¹­_ê²€ì¦
        billing_verification = create_billing_verification_report(df, all_months)
        billing_verification.to_excel(writer, sheet_name="08_ì²­êµ¬ë§¤ì¹­_ê²€ì¦")
        ws8 = writer.sheets["08_ì²­êµ¬ë§¤ì¹­_ê²€ì¦"]
        apply_conditional_formatting(workbook, ws8, billing_verification, "08_ì²­êµ¬ë§¤ì¹­_ê²€ì¦")
    
    print(f"âœ… Excel ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {output_path}")
    return output_path

# ===============================================================================
# 5. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ===============================================================================

def run_complete_ontology_8sheet_pipeline():
    """
    ì „ì²´ ìë™í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰:
    ì˜¨í†¨ë¡œì§€ ë°ì´í„° â†’ í•„ë“œ ë§¤í•‘ â†’ ë³€í™˜/ì •ê·œí™” â†’ BI ë¶„ì„ â†’ 8ì‹œíŠ¸ Excel ë¦¬í¬íŠ¸
    """
    
    print("ğŸš€ HVDC ì˜¨í†¨ë¡œì§€â†’8ì‹œíŠ¸ BI ë¦¬í¬íŠ¸ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("=" * 80)
    
    start_time = datetime.now()
    
    try:
        # 1ë‹¨ê³„: ì˜¨í†¨ë¡œì§€â†’ë§¤í•‘ DataFrame ë³€í™˜
        df, mapping_rules = load_ontology_mapping_data()
        
        # 2ë‹¨ê³„: ì „ì²˜ë¦¬Â·ì •ê·œí™” ë° ì›”ë³„ ì§‘ê³„ ì „ì²´ì›” ë³´ì¥
        df, all_months = prepare_monthly_aggregation(df)
        
        # 3ë‹¨ê³„: 8ê°œ ì‹œíŠ¸ Excel ë¦¬í¬íŠ¸ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M')
        output_path = f"HVDC_8Sheet_BI_Report_{timestamp}.xlsx"
        
        final_path = save_8sheet_excel_report(df, all_months, output_path)
        
        # 4ë‹¨ê³„: ìµœì¢… ê²€ì¦ ë° ìš”ì•½
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        
        print("\n" + "=" * 80)
        print("ğŸ‰ HVDC ì˜¨í†¨ë¡œì§€â†’8ì‹œíŠ¸ BI ë¦¬í¬íŠ¸ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        print("=" * 80)
        
        print(f"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
        print(f"   â€¢ ë°ì´í„° ê±´ìˆ˜: {len(df):,}ê±´")
        print(f"   â€¢ ì „ì²´ ì›” ë²”ìœ„: {len(all_months)}ê°œì›” ({all_months[0]} ~ {all_months[-1]})")
        print(f"   â€¢ ë§¤í•‘ëœ í•„ë“œ: {len(mapping_rules)}ê°œ")
        print(f"   â€¢ ìƒì„±ëœ ì‹œíŠ¸: 8ê°œ")
        print(f"   â€¢ ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
        print(f"   â€¢ ì¶œë ¥ íŒŒì¼: {final_path}")
        
        print(f"\nâœ… ê²€ì¦ í¬ì¸íŠ¸:")
        print(f"   âœ… ì˜¨í†¨ë¡œì§€ ë§¤í•‘: mapping_rules_v2.6_unified.json ì ìš©")
        print(f"   âœ… ì „ì²´ì›” ë³´ì¥: ëª¨ë“  ì›”ë³„ ì§‘ê³„ì—ì„œ reindex(all_months, fill_value=0) ì ìš©")
        print(f"   âœ… ì¡°ê±´ë¶€ ì„œì‹: 8ê°œ ì‹œíŠ¸ ëª¨ë‘ 3-Color Scale ì ìš©")
        print(f"   âœ… BI ë¶„ì„: ê³µê¸‰ì‚¬/ì°½ê³ /í˜„ì¥/ì…ì¶œê³ /ì¬ê³ /ì²­êµ¬ ë§¤ì¹­ ì™„ë£Œ")
        
        return final_path, df, all_months
        
    except Exception as e:
        print(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None, None, None

# ===============================================================================
# ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ ì™„ì „ ìë™í™” ë¶„ë¥˜ ì‹œìŠ¤í…œ (v4)
# ===============================================================================

# ì˜¨í†¨ë¡œì§€ì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ì •ì˜ëœ ê·¸ë£¹
INDOOR_WAREHOUSE = ["DSV Indoor", "DSV Al Markaz", "Hauler Indoor"]
OUTDOOR_WAREHOUSE = ["DSV Outdoor", "DSV MZP", "MOSB"]
SITE = ["AGI", "DAS", "MIR", "SHU"]
DANGEROUS_CARGO = ["AAA Storage", "Dangerous Storage"]

def get_location_group_ontology(name):
    """ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ ìœ„ì¹˜ ê·¸ë£¹ ë¶„ë¥˜ (100% ëª…ì‹œì  ë§¤ì¹­)"""
    if pd.isna(name):
        return "UNKNOWN"
    
    # ì •í™•í•œ ë¬¸ìì—´ ë§¤ì¹­ë§Œ ìˆ˜í–‰ (íŒ¨í„´ ë§¤ì¹­ ê¸ˆì§€)
    n = str(name).strip()
    
    if n in INDOOR_WAREHOUSE:
        return "IndoorWarehouse"
    elif n in OUTDOOR_WAREHOUSE:
        return "OutdoorWarehouse"
    elif n in SITE:
        return "Site"
    elif n in DANGEROUS_CARGO:
        return "DangerousCargoWarehouse"
    else:
        return "UNKNOWN"

def validate_ontology_location_data(df, location_column='hasSite'):
    """ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ ìœ„ì¹˜ ë°ì´í„° ê²€ì¦ ë° ë¶„ì„"""
    print("ğŸ” ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ ìœ„ì¹˜ ë°ì´í„° ê²€ì¦ ì¤‘...")
    
    if location_column not in df.columns:
        return {"error": f"ì»¬ëŸ¼ '{location_column}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}
    
    # ìœ„ì¹˜ ê·¸ë£¹ ë¶„ë¥˜
    df_temp = df.copy()
    df_temp['LocationGroup'] = df_temp[location_column].apply(get_location_group_ontology)
    
    # ë¶„ì„ ê²°ê³¼
    location_counts = df_temp[location_column].value_counts()
    group_counts = df_temp['LocationGroup'].value_counts()
    
    # ì•Œë ¤ì§€ì§€ ì•Šì€ ìœ„ì¹˜ë“¤
    unknown_locations = df_temp[df_temp['LocationGroup'] == 'UNKNOWN'][location_column].value_counts()
    
    result = {
        "total_records": len(df_temp),
        "unique_locations": len(location_counts),
        "location_distribution": location_counts.to_dict(),
        "group_distribution": group_counts.to_dict(),
        "unknown_locations": unknown_locations.to_dict(),
        "validation_summary": {
            "indoor_warehouse": len(df_temp[df_temp['LocationGroup'] == 'IndoorWarehouse']),
            "outdoor_warehouse": len(df_temp[df_temp['LocationGroup'] == 'OutdoorWarehouse']),
            "site": len(df_temp[df_temp['LocationGroup'] == 'Site']),
            "dangerous_cargo": len(df_temp[df_temp['LocationGroup'] == 'DangerousCargoWarehouse']),
            "unknown": len(df_temp[df_temp['LocationGroup'] == 'UNKNOWN'])
        }
    }
    
    print("âœ… ìœ„ì¹˜ ë°ì´í„° ê²€ì¦ ì™„ë£Œ")
    print(f"ğŸ“Š ê·¸ë£¹ë³„ ë¶„í¬: {result['group_distribution']}")
    
    if unknown_locations.any():
        print(f"âš ï¸ ì•Œë ¤ì§€ì§€ ì•Šì€ ìœ„ì¹˜ {len(unknown_locations)}ê°œ ë°œê²¬:")
        print(unknown_locations.head())
    
    return result

def create_ontology_warehouse_flow_v4(df, all_months, location_column='hasSite'):
    """ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ ì°½ê³ ë³„ ì›”ë³„ ì…ê³ /ì¶œê³ /ì¬ê³  íë¦„ ë¶„ì„ v4"""
    print("ğŸ”„ ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ ì°½ê³ ë³„ ì›”ë³„ ì…ì¶œê³  íë¦„ ë¶„ì„ v4 ì‹œì‘...")
    
    df_work = df.copy()
    
    # 1. ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ ìœ„ì¹˜ ê·¸ë£¹ ë¶„ë¥˜
    df_work['LocationGroup'] = df_work[location_column].apply(get_location_group_ontology)
    
    # 2. ì°½ê³ ë§Œ í•„í„°ë§ (í˜„ì¥ ì œì™¸)
    warehouse_groups = ['IndoorWarehouse', 'OutdoorWarehouse', 'DangerousCargoWarehouse']
    warehouse_df = df_work[df_work['LocationGroup'].isin(warehouse_groups)].copy()
    
    if warehouse_df.empty:
        print("âš ï¸ ì°½ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    
    print(f"ğŸ“Š ì°½ê³  ë°ì´í„° í•„í„°ë§ ê²°ê³¼: {len(warehouse_df):,}ê°œ ë ˆì½”ë“œ")
    
    # 3. ì›”ë³„ ì»¬ëŸ¼ ìƒì„±
    warehouse_df['Month'] = pd.to_datetime(warehouse_df['hasDate']).dt.to_period("M")
    
    print(f"ğŸ“… ë¶„ì„ ê¸°ê°„: {all_months[0]} ~ {all_months[-1]} ({len(all_months)}ê°œì›”)")
    
    # 4. ì…ê³ /ì¶œê³  ìˆ˜ëŸ‰ ë¶„ë¦¬ (ëª¨ë“  ë°ì´í„°ë¥¼ ì…ê³ ë¡œ ê°€ì •)
    quantity_col = 'hasVolume_numeric' if 'hasVolume_numeric' in warehouse_df.columns else 'hasVolume'
    amount_col = 'hasAmount_numeric' if 'hasAmount_numeric' in warehouse_df.columns else 'hasAmount'
    
    if quantity_col not in warehouse_df.columns:
        warehouse_df[quantity_col] = 0
    if amount_col not in warehouse_df.columns:
        warehouse_df[amount_col] = 0
    
    warehouse_df['InQty'] = warehouse_df[quantity_col]
    warehouse_df['OutQty'] = 0  # ì¶œê³  ë°ì´í„°ê°€ ë³„ë„ë¡œ ì—†ìœ¼ë¯€ë¡œ 0ìœ¼ë¡œ ì„¤ì •
    
    # 5. ì›”ë³„ ì§‘ê³„
    monthly_flow = warehouse_df.groupby([location_column, 'LocationGroup', 'Month']).agg({
        'InQty': 'sum',
        'OutQty': 'sum',
        amount_col: 'sum'
    }).round(2)
    
    # 6. ì¬ê³  ê³„ì‚° (ëˆ„ì  ì…ê³ )
    monthly_flow['ì¬ê³ '] = monthly_flow.groupby(level=[0, 1])['InQty'].cumsum()
    
    # 7. ì „ì²´ ì›” ë²”ìœ„ë¡œ reindex
    warehouse_list = monthly_flow.index.get_level_values(0).unique()
    
    # ìœ„ì¹˜ë³„ ê·¸ë£¹ ë§¤í•‘ ìƒì„±
    location_group_map = warehouse_df.drop_duplicates([location_column, 'LocationGroup']).set_index(location_column)['LocationGroup'].to_dict()
    
    multi_index_data = []
    for location in warehouse_list:
        group = location_group_map[location]
        for month in all_months:
            multi_index_data.append((location, group, month))
    
    multi_index = pd.MultiIndex.from_tuples(
        multi_index_data, 
        names=[location_column, 'LocationGroup', 'Month']
    )
    
    monthly_flow = monthly_flow.reindex(multi_index, fill_value=0)
    
    # 8. ìµœì¢… í¬ë§·íŒ…
    result = monthly_flow.reset_index()
    result.columns = ['ì°½ê³ ëª…', 'ìœ„ì¹˜ê·¸ë£¹', 'ì›”', 'ì…ê³ ', 'ì¶œê³ ', 'ê¸ˆì•¡', 'ì¬ê³ ']
    
    print(f"âœ… ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ ì°½ê³ ë³„ íë¦„ ë¶„ì„ ì™„ë£Œ: {len(warehouse_list)}ê°œ ì°½ê³ , {len(all_months)}ê°œì›”")
    
    return result

def create_ontology_site_delivery_v4(df, all_months, location_column='hasSite'):
    """ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ í˜„ì¥ë³„ ë°°ì†¡ í˜„í™© ë¶„ì„ v4"""
    print("ğŸ”„ ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ í˜„ì¥ë³„ ë°°ì†¡ í˜„í™© ë¶„ì„ v4 ì‹œì‘...")
    
    df_work = df.copy()
    
    # 1. ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ ìœ„ì¹˜ ê·¸ë£¹ ë¶„ë¥˜
    df_work['LocationGroup'] = df_work[location_column].apply(get_location_group_ontology)
    
    # 2. í˜„ì¥ë§Œ í•„í„°ë§
    site_df = df_work[df_work['LocationGroup'] == 'Site'].copy()
    
    if site_df.empty:
        print("âš ï¸ í˜„ì¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    
    print(f"ğŸ“Š í˜„ì¥ ë°ì´í„° í•„í„°ë§ ê²°ê³¼: {len(site_df):,}ê°œ ë ˆì½”ë“œ")
    
    # 3. ì›”ë³„ ì§‘ê³„
    site_df['Month'] = pd.to_datetime(site_df['hasDate']).dt.to_period("M")
    
    quantity_col = 'hasVolume_numeric' if 'hasVolume_numeric' in site_df.columns else 'hasVolume'
    amount_col = 'hasAmount_numeric' if 'hasAmount_numeric' in site_df.columns else 'hasAmount'
    
    if quantity_col not in site_df.columns:
        site_df[quantity_col] = 0
    if amount_col not in site_df.columns:
        site_df[amount_col] = 0
    
    site_delivery = site_df.groupby([location_column, 'Month']).agg({
        quantity_col: ['sum', 'count'],
        amount_col: 'sum'
    }).round(2)
    
    # ì»¬ëŸ¼ëª… ì •ë¦¬
    site_delivery.columns = ['ë°°ì†¡ìˆ˜ëŸ‰', 'ë°°ì†¡íšŸìˆ˜', 'ë°°ì†¡ê¸ˆì•¡']
    
    # 4. ì „ì²´ ì›” ë²”ìœ„ë¡œ reindex
    site_list = site_delivery.index.get_level_values(0).unique()
    multi_index = pd.MultiIndex.from_product(
        [site_list, all_months], 
        names=[location_column, 'Month']
    )
    
    site_delivery = site_delivery.reindex(multi_index, fill_value=0)
    
    # 5. ìµœì¢… í¬ë§·íŒ…
    result = site_delivery.reset_index()
    result.columns = ['í˜„ì¥ëª…', 'ì›”', 'ë°°ì†¡ìˆ˜ëŸ‰', 'ë°°ì†¡íšŸìˆ˜', 'ë°°ì†¡ê¸ˆì•¡']
    
    print(f"âœ… ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ í˜„ì¥ë³„ ë°°ì†¡ ë¶„ì„ ì™„ë£Œ: {len(site_list)}ê°œ í˜„ì¥, {len(all_months)}ê°œì›”")
    
    return result

def run_ontology_8sheet_pipeline_v4(excel_path=None, mapping_rules_path=None):
    """ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ 8ì‹œíŠ¸ ë¦¬í¬íŠ¸ íŒŒì´í”„ë¼ì¸ v4 ì‹¤í–‰"""
    print("ğŸ¯ ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ HVDC 8ì‹œíŠ¸ ë¦¬í¬íŠ¸ íŒŒì´í”„ë¼ì¸ v4 ì‹œì‘")
    print("=" * 80)
    
    start_time = datetime.now()
    
    try:
        # 1. ë°ì´í„° ë¡œë“œ ë° ë§¤í•‘
        if excel_path is None:
            excel_path = "data/HVDC WAREHOUSE_HITACHI(HE).xlsx"
        
        if mapping_rules_path is None:
            mapping_rules_path = "mapping_rules_v2.6_unified.json"
        
        print(f"ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘: {excel_path}")
        print(f"ğŸ“‹ ë§¤í•‘ ê·œì¹™: {mapping_rules_path}")
        
        # ë§¤í•‘ ê·œì¹™ ë¡œë“œ
        with open(mapping_rules_path, encoding='utf-8') as f:
            mapping_rules = json.load(f)['field_map']
        
        # ì›ë³¸ ë°ì´í„° ë¡œë“œ ë° ë§¤í•‘
        df_raw = pd.read_excel(excel_path)
        col_map = {k: v for k, v in mapping_rules.items() if k in df_raw.columns}
        df = df_raw.rename(columns=col_map)
        
        # í•„ìš” ì»¬ëŸ¼ ì¶”ê°€
        for needed in mapping_rules.values():
            if needed not in df.columns:
                df[needed] = 0
        
        # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
        date_cols = ['ETD/ATD', 'ETA/ATA']
        for col in date_cols:
            if col in df_raw.columns:
                df['hasDate'] = pd.to_datetime(df_raw[col], errors='coerce')
                break
        else:
            df['hasDate'] = pd.Timestamp.now()
        
        df['hasDate'] = df['hasDate'].fillna(pd.Timestamp.now())
        
        # ìˆ˜ì¹˜ ì»¬ëŸ¼ ì²˜ë¦¬
        df['hasAmount_numeric'] = pd.to_numeric(df['hasAmount'], errors='coerce').fillna(0)
        df['hasVolume_numeric'] = pd.to_numeric(df['hasVolume'], errors='coerce').fillna(0)
        
        print(f"âœ… ë°ì´í„° ë¡œë“œ ë° ë§¤í•‘ ì™„ë£Œ: {df.shape[0]:,}ê°œ ë ˆì½”ë“œ, {df.shape[1]}ê°œ ì»¬ëŸ¼")
        
        # 2. ì›”ë³„ ì§‘ê³„ ì¤€ë¹„
        df['Billing Month'] = pd.to_datetime(df['hasDate']).dt.to_period("M")
        all_months = pd.period_range(df['Billing Month'].min(), df['Billing Month'].max(), freq='M')
        
        # 3. ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ ë¶„ì„
        df['LocationGroup'] = df['hasSite'].apply(get_location_group_ontology)
        
        # 4. ë¦¬í¬íŠ¸ ìƒì„±
        reports = {}
        
        # ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ ì°½ê³ ë³„ ì›”ë³„ ì…ì¶œê³  íë¦„
        warehouse_flow = create_ontology_warehouse_flow_v4(df, all_months)
        if not warehouse_flow.empty:
            reports['ì°½ê³ ë³„_ì›”ë³„_ì…ì¶œê³ ì¬ê³ '] = warehouse_flow
        
        # ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ í˜„ì¥ë³„ ë°°ì†¡ í˜„í™©
        site_delivery = create_ontology_site_delivery_v4(df, all_months)
        if not site_delivery.empty:
            reports['í˜„ì¥ë³„_ë°°ì†¡í˜„í™©'] = site_delivery
        
        # ì˜¨í†¨ë¡œì§€ ë¶„ë¥˜ ê²°ê³¼ ìš”ì•½
        validation_result = df['LocationGroup'].value_counts().to_dict()
        reports['ì˜¨í†¨ë¡œì§€_ë¶„ë¥˜ê²°ê³¼'] = pd.DataFrame([
            {"ë¶„ë¥˜": "Indoor Warehouse", "ìœ„ì¹˜": ", ".join(INDOOR_WAREHOUSE), "ê±´ìˆ˜": validation_result.get('IndoorWarehouse', 0)},
            {"ë¶„ë¥˜": "Outdoor Warehouse", "ìœ„ì¹˜": ", ".join(OUTDOOR_WAREHOUSE), "ê±´ìˆ˜": validation_result.get('OutdoorWarehouse', 0)},
            {"ë¶„ë¥˜": "Site", "ìœ„ì¹˜": ", ".join(SITE), "ê±´ìˆ˜": validation_result.get('Site', 0)},
            {"ë¶„ë¥˜": "Dangerous Cargo", "ìœ„ì¹˜": ", ".join(DANGEROUS_CARGO), "ê±´ìˆ˜": validation_result.get('DangerousCargoWarehouse', 0)},
            {"ë¶„ë¥˜": "UNKNOWN", "ìœ„ì¹˜": "ì•Œë ¤ì§€ì§€ ì•Šì€ ìœ„ì¹˜", "ê±´ìˆ˜": validation_result.get('UNKNOWN', 0)}
        ])
        
        # 5. Excel ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M')
        output_path = f"HVDC_ì˜¨í†¨ë¡œì§€ê¸°ì¤€_8ì‹œíŠ¸ë¦¬í¬íŠ¸_{timestamp}.xlsx"
        
        print(f"ğŸ’¾ ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ 8ì‹œíŠ¸ Excel ë¦¬í¬íŠ¸ ì €ì¥ ì¤‘: {output_path}")
        
        with pd.ExcelWriter(output_path, engine="xlsxwriter") as writer:
            for sheet_name, report_df in reports.items():
                if isinstance(report_df, pd.DataFrame):
                    safe_sheet_name = sheet_name[:31] if len(sheet_name) > 31 else sheet_name
                    report_df.to_excel(writer, sheet_name=safe_sheet_name, index=False)
        
        # 6. ê²°ê³¼ ìš”ì•½
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        
        print("\n" + "=" * 80)
        print("ğŸ‰ ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ HVDC 8ì‹œíŠ¸ ë¦¬í¬íŠ¸ íŒŒì´í”„ë¼ì¸ v4 ì™„ë£Œ!")
        print("=" * 80)
        
        print(f"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
        print(f"   â€¢ ì›ë³¸ ë°ì´í„°: {df.shape[0]:,}ê°œ ë ˆì½”ë“œ")
        print(f"   â€¢ ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
        print(f"   â€¢ Excel íŒŒì¼: {output_path}")
        print(f"   â€¢ ìƒì„±ëœ ì‹œíŠ¸: {len([k for k, v in reports.items() if isinstance(v, pd.DataFrame)])}ê°œ")
        
        return reports, output_path
        
    except Exception as e:
        print(f"âŒ ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ 8ì‹œíŠ¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return {}, None

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="HVDC ì°½ê³  ê´€ë¦¬ ì‹œìŠ¤í…œ - ê³ ê¸‰ 8ê°œ ì‹œíŠ¸ ë¦¬í¬íŠ¸ ìƒì„±ê¸°")
    parser.add_argument("--mode", choices=['amount', 'qty', 'flow', 'ontology'], default='amount', 
                        help="ë¦¬í¬íŠ¸ ëª¨ë“œ (amount: ê¸ˆì•¡ì¤‘ì‹¬, qty: ìˆ˜ëŸ‰ì¤‘ì‹¬, flow: ì°½ê³ íë¦„ì¤‘ì‹¬, ontology: ì˜¨í†¨ë¡œì§€ê¸°ì¤€)")
    parser.add_argument("--version", choices=['v1', 'v2', 'v3', 'v4'], default='v1', 
                        help="í•¨ìˆ˜ ë²„ì „ (v1: ê¸°ë³¸, v2: ê°œì„ , v3: ì°½ê³ íë¦„, v4: ì˜¨í†¨ë¡œì§€ê¸°ì¤€)")
    parser.add_argument("--output", type=str, default=None, 
                        help="ì¶œë ¥ íŒŒì¼ëª… (ê¸°ë³¸ê°’: ìë™ ìƒì„±)")
    parser.add_argument("--flow-analysis", action='store_true', 
                        help="ì°½ê³  íë¦„ ë¶„ì„ ì‹¤í–‰")
    
    args = parser.parse_args()
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    if args.mode == 'ontology' or args.version == 'v4':
        result, excel_path = run_ontology_8sheet_pipeline_v4()
        if result:
            print(f"\nğŸ‰ ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ ì‹¤í–‰ ì™„ë£Œ! ê²°ê³¼ íŒŒì¼: {excel_path}")
        else:
            print(f"\nâŒ ì˜¨í†¨ë¡œì§€ ê¸°ì¤€ ì‹¤í–‰ ì‹¤íŒ¨!")
    elif args.mode == 'flow':
        result = run_warehouse_flow_8sheet_pipeline_v3()
        if result:
            print(f"\nğŸ‰ ì°½ê³  íë¦„ ì‹¤í–‰ ì™„ë£Œ! ê²°ê³¼ íŒŒì¼: {result.get('_excel_path', 'N/A')}")
        else:
            print(f"\nâŒì°½ê³  íë¦„ ì‹¤í–‰ ì‹¤íŒ¨!")
    else:
        result = run_advanced_hvdc_pipeline_with_flow(
            mode=args.mode,
            version=args.version,
            output=args.output,
            flow_analysis=args.flow_analysis
        )
        if result:
            print(f"\nğŸ‰ ì‹¤í–‰ ì™„ë£Œ! ê²°ê³¼ íŒŒì¼: {result.get('_excel_path', 'N/A')}")
        else:
            print(f"\nâŒ ì‹¤í–‰ ì‹¤íŒ¨!")