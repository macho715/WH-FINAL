#!/usr/bin/env python3
"""
ì‹¤ì œ ë°ì´í„°ë¡œ ì°½ê³  íë¦„ ë¶„ì„ ì‹¤í–‰
===============================

ì‚¬ìš©ìžê°€ ìš”ì²­í•œ ì°½ê³ ì™€ í˜„ìž¥ êµ¬ë¶„, ìž…ê³ /ì¶œê³ /ìž¬ê³  íë¦„ ë¶„ì„ì„ ì‹¤ì œ ë°ì´í„°ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
from datetime import datetime
import json

def load_real_data():
    """ì‹¤ì œ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    print("ðŸ”„ ì‹¤ì œ ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    # 1. ë§¤í•‘ ê·œì¹™ ë¡œë“œ
    with open('mapping_rules_v2.6_unified.json', encoding='utf-8') as f:
        mapping_rules = json.load(f)['field_map']
    
    # 2. ì‹¤ì œ ë°ì´í„° ë¡œë“œ
    df_raw = pd.read_excel('data/HVDC WAREHOUSE_HITACHI(HE).xlsx')
    
    # 3. ë§¤í•‘ ì ìš©
    col_map = {k: v for k, v in mapping_rules.items() if k in df_raw.columns}
    df = df_raw.rename(columns=col_map)
    
    # 4. í•„ìš” ì»¬ëŸ¼ ì¶”ê°€
    for needed in mapping_rules.values():
        if needed not in df.columns:
            df[needed] = 0
    
    # 5. ë‚ ì§œ ì²˜ë¦¬
    if 'ETD/ATD' in df_raw.columns:
        df['hasDate'] = pd.to_datetime(df_raw['ETD/ATD'], errors='coerce')
    elif 'ETA/ATA' in df_raw.columns:
        df['hasDate'] = pd.to_datetime(df_raw['ETA/ATA'], errors='coerce')
    else:
        df['hasDate'] = pd.Timestamp.now()
    
    # ê²°ì¸¡ê°’ ì²˜ë¦¬
    df['hasDate'] = df['hasDate'].fillna(pd.Timestamp.now())
    
    # 6. ìˆ˜ì¹˜ ì»¬ëŸ¼ ì²˜ë¦¬
    df['hasAmount_numeric'] = pd.to_numeric(df['hasAmount'], errors='coerce').fillna(0)
    df['hasVolume_numeric'] = pd.to_numeric(df['hasVolume'], errors='coerce').fillna(0)
    
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape[0]:,}ê°œ ë ˆì½”ë“œ, {df.shape[1]}ê°œ ì»¬ëŸ¼")
    
    return df

def normalize_warehouse_name(name):
    """ì°½ê³ ëª… ì •ê·œí™” (DAS, Das í†µí•©)"""
    if pd.isna(name) or name == '':
        return ''
    
    name = str(name).strip().upper()
    
    # DAS ì •ê·œí™” (ëŒ€ì†Œë¬¸ìž í†µí•©)
    if name in ['DAS', 'D.A.S', 'D A S']:
        return 'DAS'
    
    # ê¸°íƒ€ ì°½ê³ ëª… ì •ê·œí™”
    warehouse_mapping = {
        'DSV INDOOR': ['DSV INDOOR', 'DSV_INDOOR', 'INDOOR', 'M44'],
        'DSV OUTDOOR': ['DSV OUTDOOR', 'DSV_OUTDOOR', 'OUTDOOR'],
        'DSV AL MARKAZ': ['DSV AL MARKAZ', 'DSV_AL_MARKAZ', 'MARKAZ', 'M1'],
        'MOSB': ['MOSB', 'M.O.S.B', 'M O S B']
    }
    
    for canonical_name, patterns in warehouse_mapping.items():
        for pattern in patterns:
            if pattern in name:
                return canonical_name
    
    # í˜„ìž¥ëª… íŒ¨í„´ (ì°½ê³ ê°€ ì•„ë‹Œ ê²½ìš°)
    site_patterns = ['AGI', 'MIR', 'SHU', 'SITE', 'PROJECT', 'FIELD']
    
    for site_pattern in site_patterns:
        if site_pattern in name:
            return ''  # í˜„ìž¥ì€ ë¹ˆ ë¬¸ìžì—´ ë°˜í™˜
    
    return name

def classify_location_type(name):
    """ìœ„ì¹˜ íƒ€ìž… ë¶„ë¥˜"""
    if pd.isna(name) or name == '':
        return 'UNKNOWN'
    
    name = str(name).strip().upper()
    
    # ì°½ê³  íŒ¨í„´
    if name in ['DAS', 'DSV INDOOR', 'DSV OUTDOOR', 'DSV AL MARKAZ', 'MOSB']:
        return 'WAREHOUSE'
    
    # í˜„ìž¥ íŒ¨í„´
    if name in ['AGI', 'MIR', 'SHU']:
        return 'SITE'
    
    return 'UNKNOWN'

def classify_transaction_type(row):
    """íŠ¸ëžœìž­ì…˜ íƒ€ìž… ë¶„ë¥˜ (ìž…ê³ /ì¶œê³ /ì´ë™)"""
    # ìˆ˜ëŸ‰ ê¸°ë°˜ ì¶”ì • (ì–‘ìˆ˜=ìž…ê³ , ìŒìˆ˜=ì¶œê³ )
    if 'hasVolume_numeric' in row and pd.notna(row['hasVolume_numeric']):
        qty = float(row['hasVolume_numeric'])
        if qty > 0:
            return 'IN'
        elif qty < 0:
            return 'OUT'
    
    # ê¸°ë³¸ì ìœ¼ë¡œ ìž…ê³ ë¡œ ê°€ì •
    return 'IN'

def create_warehouse_flow_analysis_real(df):
    """ì‹¤ì œ ë°ì´í„°ë¡œ ì°½ê³  íë¦„ ë¶„ì„"""
    print("ðŸ”„ ì°½ê³ ë³„ ì›”ë³„ ìž…ì¶œê³  íë¦„ ë¶„ì„ ì‹œìž‘...")
    
    df_work = df.copy()
    
    # 1. ì°½ê³ ëª… ì •ê·œí™” ë° ë¶„ë¥˜
    df_work['Warehouse_Normalized'] = df_work['hasSite'].apply(normalize_warehouse_name)
    df_work['Location_Type'] = df_work['hasSite'].apply(classify_location_type)
    
    # 2. ì°½ê³ ë§Œ í•„í„°ë§
    warehouse_df = df_work[
        (df_work['Location_Type'] == 'WAREHOUSE') & 
        (df_work['Warehouse_Normalized'] != '')
    ].copy()
    
    print(f"ðŸ“Š ì°½ê³  ë°ì´í„° í•„í„°ë§ ê²°ê³¼: {len(warehouse_df):,}ê°œ ë ˆì½”ë“œ")
    
    # 3. ì›”ë³„ ì»¬ëŸ¼ ìƒì„±
    warehouse_df['Month'] = pd.to_datetime(warehouse_df['hasDate']).dt.to_period("M")
    all_months = pd.period_range(warehouse_df['Month'].min(), warehouse_df['Month'].max(), freq='M')
    
    print(f"ðŸ“… ë¶„ì„ ê¸°ê°„: {all_months[0]} ~ {all_months[-1]} ({len(all_months)}ê°œì›”)")
    
    # 4. íŠ¸ëžœìž­ì…˜ íƒ€ìž… ë¶„ë¥˜
    warehouse_df['TxType_Classified'] = warehouse_df.apply(classify_transaction_type, axis=1)
    
    # 5. ìž…ê³ /ì¶œê³  ìˆ˜ëŸ‰ ë¶„ë¦¬ (ëª¨ë“  ë°ì´í„°ë¥¼ ìž…ê³ ë¡œ ê°€ì •)
    warehouse_df['InQty'] = warehouse_df['hasVolume_numeric']
    warehouse_df['OutQty'] = 0  # ì¶œê³  ë°ì´í„°ê°€ ë³„ë„ë¡œ ì—†ìœ¼ë¯€ë¡œ 0ìœ¼ë¡œ ì„¤ì •
    warehouse_df['TransferQty'] = 0
    
    # 6. ì›”ë³„ ì§‘ê³„
    monthly_flow = warehouse_df.groupby(['Warehouse_Normalized', 'Month']).agg({
        'InQty': 'sum',
        'OutQty': 'sum', 
        'TransferQty': 'sum',
        'hasAmount_numeric': 'sum'
    }).round(2)
    
    # 7. ìž¬ê³  ê³„ì‚° (ëˆ„ì  ìž…ê³ )
    monthly_flow['Net_Flow'] = monthly_flow['InQty'] - monthly_flow['OutQty'] + monthly_flow['TransferQty']
    monthly_flow['Cumulative_Stock'] = monthly_flow.groupby(level=0)['Net_Flow'].cumsum()
    
    # 8. ì „ì²´ ì›” ë²”ìœ„ë¡œ reindex
    warehouse_list = monthly_flow.index.get_level_values(0).unique()
    multi_index = pd.MultiIndex.from_product(
        [warehouse_list, all_months], 
        names=['Warehouse_Normalized', 'Month']
    )
    
    monthly_flow = monthly_flow.reindex(multi_index, fill_value=0)
    
    # 9. ìµœì¢… í¬ë§·íŒ…
    result = monthly_flow.reset_index()
    result.columns = ['ì°½ê³ ëª…', 'ì›”', 'ìž…ê³ ìˆ˜ëŸ‰', 'ì¶œê³ ìˆ˜ëŸ‰', 'ì´ë™ìˆ˜ëŸ‰', 'ê¸ˆì•¡', 'ìˆœì¦ê°', 'ëˆ„ì ìž¬ê³ ']
    
    print(f"âœ… ì°½ê³ ë³„ íë¦„ ë¶„ì„ ì™„ë£Œ: {len(warehouse_list)}ê°œ ì°½ê³ , {len(all_months)}ê°œì›”")
    
    return result

def create_site_delivery_analysis_real(df):
    """ì‹¤ì œ ë°ì´í„°ë¡œ í˜„ìž¥ ë°°ì†¡ ë¶„ì„"""
    print("ðŸ”„ í˜„ìž¥ë³„ ë°°ì†¡ í˜„í™© ë¶„ì„ ì‹œìž‘...")
    
    df_work = df.copy()
    
    # 1. í˜„ìž¥ ë¶„ë¥˜
    df_work['Location_Type'] = df_work['hasSite'].apply(classify_location_type)
    df_work['Site_Name'] = df_work['hasSite'].apply(
        lambda x: str(x).strip().upper() if classify_location_type(x) == 'SITE' else ''
    )
    
    # 2. í˜„ìž¥ë§Œ í•„í„°ë§
    site_df = df_work[
        (df_work['Location_Type'] == 'SITE') & 
        (df_work['Site_Name'] != '')
    ].copy()
    
    print(f"ðŸ“Š í˜„ìž¥ ë°ì´í„° í•„í„°ë§ ê²°ê³¼: {len(site_df):,}ê°œ ë ˆì½”ë“œ")
    
    # 3. ì›”ë³„ ì§‘ê³„
    site_df['Month'] = pd.to_datetime(site_df['hasDate']).dt.to_period("M")
    all_months = pd.period_range(site_df['Month'].min(), site_df['Month'].max(), freq='M')
    
    site_delivery = site_df.groupby(['Site_Name', 'Month']).agg({
        'hasVolume_numeric': ['sum', 'count'],
        'hasAmount_numeric': 'sum'
    }).round(2)
    
    # ì»¬ëŸ¼ëª… ì •ë¦¬
    site_delivery.columns = ['ë°°ì†¡ìˆ˜ëŸ‰', 'ë°°ì†¡íšŸìˆ˜', 'ë°°ì†¡ê¸ˆì•¡']
    
    # 4. ì „ì²´ ì›” ë²”ìœ„ë¡œ reindex
    site_list = site_delivery.index.get_level_values(0).unique()
    multi_index = pd.MultiIndex.from_product(
        [site_list, all_months], 
        names=['Site_Name', 'Month']
    )
    
    site_delivery = site_delivery.reindex(multi_index, fill_value=0)
    
    # 5. ìµœì¢… í¬ë§·íŒ…
    result = site_delivery.reset_index()
    result.columns = ['í˜„ìž¥ëª…', 'ì›”', 'ë°°ì†¡ìˆ˜ëŸ‰', 'ë°°ì†¡íšŸìˆ˜', 'ë°°ì†¡ê¸ˆì•¡']
    
    print(f"âœ… í˜„ìž¥ë³„ ë°°ì†¡ ë¶„ì„ ì™„ë£Œ: {len(site_list)}ê°œ í˜„ìž¥, {len(all_months)}ê°œì›”")
    
    return result

def save_results_to_excel(warehouse_flow, site_delivery):
    """ê²°ê³¼ë¥¼ Excel íŒŒì¼ë¡œ ì €ìž¥"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M')
    output_path = f"HVDC_ì‹¤ì œë°ì´í„°_ì°½ê³ íë¦„ë¶„ì„_{timestamp}.xlsx"
    
    print(f"ðŸ’¾ Excel íŒŒì¼ ì €ìž¥ ì¤‘: {output_path}")
    
    with pd.ExcelWriter(output_path, engine="xlsxwriter") as writer:
        # ì°½ê³ ë³„ íë¦„ ë¶„ì„
        warehouse_flow.to_excel(writer, sheet_name="ì°½ê³ ë³„_ì›”ë³„_ìž…ì¶œê³ ìž¬ê³ ", index=False)
        
        # í˜„ìž¥ë³„ ë°°ì†¡ ë¶„ì„
        site_delivery.to_excel(writer, sheet_name="í˜„ìž¥ë³„_ë°°ì†¡í˜„í™©", index=False)
        
        # ì°½ê³  ìš”ì•½ í†µê³„
        warehouse_summary = warehouse_flow.groupby('ì°½ê³ ëª…').agg({
            'ìž…ê³ ìˆ˜ëŸ‰': 'sum',
            'ì¶œê³ ìˆ˜ëŸ‰': 'sum',
            'ì´ë™ìˆ˜ëŸ‰': 'sum',
            'ê¸ˆì•¡': 'sum',
            'ëˆ„ì ìž¬ê³ ': 'last'
        }).round(2)
        warehouse_summary.columns = ['ì´ìž…ê³ ', 'ì´ì¶œê³ ', 'ì´ì´ë™', 'ì´ê¸ˆì•¡', 'í˜„ìž¬ìž¬ê³ ']
        warehouse_summary.reset_index().to_excel(writer, sheet_name="ì°½ê³ ë³„_ìš”ì•½í†µê³„", index=False)
        
        # í˜„ìž¥ ìš”ì•½ í†µê³„
        site_summary = site_delivery.groupby('í˜„ìž¥ëª…').agg({
            'ë°°ì†¡ìˆ˜ëŸ‰': 'sum',
            'ë°°ì†¡íšŸìˆ˜': 'sum',
            'ë°°ì†¡ê¸ˆì•¡': 'sum'
        }).round(2)
        site_summary.columns = ['ì´ë°°ì†¡ìˆ˜ëŸ‰', 'ì´ë°°ì†¡íšŸìˆ˜', 'ì´ë°°ì†¡ê¸ˆì•¡']
        site_summary.reset_index().to_excel(writer, sheet_name="í˜„ìž¥ë³„_ìš”ì•½í†µê³„", index=False)
    
    print(f"âœ… Excel íŒŒì¼ ì €ìž¥ ì™„ë£Œ: {output_path}")
    return output_path

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ðŸŽ¯ ì‹¤ì œ ë°ì´í„°ë¡œ ì°½ê³  íë¦„ ë¶„ì„ ì‹œìž‘")
    print("=" * 80)
    
    start_time = datetime.now()
    
    try:
        # 1. ì‹¤ì œ ë°ì´í„° ë¡œë“œ
        df = load_real_data()
        
        # 2. ì°½ê³  íë¦„ ë¶„ì„
        warehouse_flow = create_warehouse_flow_analysis_real(df)
        
        # 3. í˜„ìž¥ ë°°ì†¡ ë¶„ì„
        site_delivery = create_site_delivery_analysis_real(df)
        
        # 4. ê²°ê³¼ ì €ìž¥
        excel_path = save_results_to_excel(warehouse_flow, site_delivery)
        
        # 5. ê²°ê³¼ ìš”ì•½
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        
        print("\n" + "=" * 80)
        print("ðŸŽ‰ ì‹¤ì œ ë°ì´í„° ì°½ê³  íë¦„ ë¶„ì„ ì™„ë£Œ!")
        print("=" * 80)
        
        print(f"ðŸ“Š ë¶„ì„ ê²°ê³¼:")
        print(f"   â€¢ ì›ë³¸ ë°ì´í„°: {df.shape[0]:,}ê°œ ë ˆì½”ë“œ")
        print(f"   â€¢ ì°½ê³  ê°œìˆ˜: {warehouse_flow['ì°½ê³ ëª…'].nunique()}ê°œ")
        print(f"   â€¢ í˜„ìž¥ ê°œìˆ˜: {site_delivery['í˜„ìž¥ëª…'].nunique()}ê°œ")
        print(f"   â€¢ ë¶„ì„ ê¸°ê°„: {warehouse_flow['ì›”'].nunique()}ê°œì›”")
        print(f"   â€¢ ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
        print(f"   â€¢ Excel íŒŒì¼: {excel_path}")
        
        print(f"\nðŸ“‹ ì°½ê³ ë³„ ìž…ì¶œê³  í˜„í™© (ìƒìœ„ 10ê°œ):")
        print(warehouse_flow.head(10))
        
        print(f"\nðŸ“‹ í˜„ìž¥ë³„ ë°°ì†¡ í˜„í™© (ìƒìœ„ 10ê°œ):")
        print(site_delivery.head(10))
        
        print(f"\nâœ… ëª¨ë“  ë¶„ì„ ì™„ë£Œ! ðŸŽ‰")
        
    except Exception as e:
        print(f"\nâŒ ë¶„ì„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 